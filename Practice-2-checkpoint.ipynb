{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4e9c93",
   "metadata": {},
   "source": [
    "## Deep Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bf24c",
   "metadata": {},
   "source": [
    "#### Concepts\n",
    "- Image Data\n",
    "- Convolutional Layer\n",
    "- Pooling Layer\n",
    "- CNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6674a7",
   "metadata": {},
   "source": [
    "The major differences we are about to see in these types of neural networks are the layers that make them up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e855a68",
   "metadata": {},
   "source": [
    "### Image Data\n",
    "We have 3 dimensional images\n",
    "- Image width\n",
    "- Image height\n",
    "- Color channel(depth of an image and coorelates to the colors used in it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d1a66",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "- Each convolutional neural network is made up of one or many convolutional layers.\n",
    "- Detect patterns globally while convolutional layers detect patterns locally.\n",
    "\n",
    "## Multiple Convolutional Layers\n",
    "In our models it is quite common to have more than one convolutional layer. Even the basic example we will use in this guide will be made up of 3 convolutional layers. These layers work together by increasing complexity and abstraction at each subsequent layer. The first layer might be responsible for picking up edges and short lines, while the second layer will take as input these lines and start forming shapes or polygons. Finally, the last layer might take these shapes and determine which combiantions make up a specific image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df477924",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "- The problem we will consider here is classifying 10 different everyday objects. The dataset we will use is built into tensorflow and called the CIFAR Image Dataset. It contains 60,000 32x32 color images with 6000 images of each class.\n",
    "\n",
    "- The labels in this dataset are the following:\n",
    "\n",
    "- Airplane\n",
    "-  Automobile\n",
    "-  Bird\n",
    "-  Cat\n",
    "-  Deer\n",
    "-  Dog\n",
    "-  Frog\n",
    "-  Horse\n",
    "-  Ship\n",
    "-  Truck\n",
    "\n",
    "We'll load the dataset and have a look at some of the images below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b7a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d22de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 469s 3us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_lables) = datasets.cifar10.load_data()\n",
    "\n",
    "train_images, test_images = train_images,test_images/255.0\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f685491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEHCAYAAABoVTBwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeVElEQVR4nO2dXYxlWXXf/+vc77pV1dU9/UHTTDI2GjvGyAy4NSEZxyLGsSbIEfAAMoqseRi5bcmjGMl+GGEpTN5IFEC8BKkJIw8RwRAPiFGEbPDI0RgpIvTgYRg8xGA8HoZu+rO+b93Ps/JwTys97f1fVd1Vdath/39Sqar2vvucdfY565579/+stczdIYT4yac4aAOEELNBzi5EJsjZhcgEObsQmSBnFyIT5OxCZEJ9N4PN7EEAHwNQA/Bf3f1D4c6adW+1W+nOQAE00h6phkWNv4/VajU+MNjopCyT7cw+ADDjvU62t924IugzcmiF8fkoS37MUZ87t59RBHMfHVckEUd9VqSPezya0DHj8Zj2IbAxuhLC64DYH83veJy2fzIeoyzL5M7sdnV2M6sB+BsA/wrAKwC+DuB97v7XbEx3ses/f/rn09sLLqpikj7oYAg63S7tO3ToEO0rAwdcX19PthfGDWk3G7Svv9mjfZ1mm/Y1m9xxW930+3erwbfX7/OLu98f8r7BFu2zIn1xz3fn6ZhWm9s4Ho9o33DIbWy1Osn2q1dW6JiLFy/Tvlqd3KwAWI2f6+gGMxqljy06ruXl5WT7lYuXMBoOk5O/m4/x9wP4nrt/392HAP4YwDt3sT0hxD6yG2c/BeAHN/z/StUmhLgD2c139tRHhX/wedbMzgA4AwDNVnMXuxNC7Ibd3NlfAXD3Df+/DsD5m1/k7mfd/bS7n643d7UeKITYBbtx9q8DuNfMfsrMmgB+A8BTe2OWEGKvue1brbuPzewRAH+GqfT2uLt/OxxTlhgMN5J9rRo3pSSKQS1Y/XRwaWWzl15VB4BGg3/V6MylV2IH0ap0nUsu84f4ynSzCE5NyVdpm0VaTVic5yvdWxt89blwPo+dDl+ZZprGcMxtR9A1N5deVQcAKwJZhshX8wtzdMiVK/ycjQJZrhbcOyPVi63GR8pQvZ6+PiKJb1efq939SwC+tJttCCFmg56gEyIT5OxCZIKcXYhMkLMLkQlydiEyYcZPuTiVxEisCwBgPBgk29ttLp/USi7LdTpc8lpcXKR9G5ubyfbhuE/HtOa45NVpcOmqFqhJgy0uh7GgnNWVa3RMOeFBJo0Gn8dREABWI1GHUUBIvc77BkM+x5H95SRtZKBqoRU86Tne4tJbJJVFsCi7aHuRxMbQnV2ITJCzC5EJcnYhMkHOLkQmyNmFyISZrsZbUaBDVtBH/fSKOwAUJCgkXpHkK5m1epCPLQj8MLLS3enyFfco8KPZCIJ/gpxbC0s8rVa9ll7ZPf/DH9ExrRZXNYog2MiCuUItfW5qDT73o2CuNjfSAVQA0Cz4Kn6DKB7RNbAYBCgNx9yOwZBfc5GqwYJaBkSFAoCFhYVk++Uoxx/tEUL8RCFnFyIT5OxCZIKcXYhMkLMLkQlydiEyYbbSmxVo1NO5xMrgbae7mB6ztZUOTAGArT4PnFhfX6N9FtShKkk+s3HJgyO6XZ47LcqT1wkCaGqBZDch798LR4/TMdFlsL7GpSYn+e4AoEECYUbO52oSSHlHTxylfU1wualk1YSCC240DGycRIEwXAqOSkox6S2qCDM3l5ZLC1LuCtCdXYhskLMLkQlydiEyQc4uRCbI2YXIBDm7EJmwK+nNzF4CsA5gAmDs7qe3GQFYOvpnfp7nY2vX02PC/Ghlj/Y1goin4YhHGoFE2UWRcu0OjyiLIv02t3hJqc0+l3jm5tMRW2VQTmpzg++rs8gj7HqbPK8dSNTewmI6WgsABoHUFMlQ7nw+mk1SsiuQZttRWauSn+uoHFkk2TEbWy1uBysZFZWZ2gud/V+6+5U92I4QYh/Rx3ghMmG3zu4Avmxmz5rZmb0wSAixP+z2Y/wD7n7ezI4D+IqZfcfdn7nxBdWbwBkAaLX5dxAhxP6yqzu7u5+vfl8C8AUA9ydec9bdT7v76XqTL2AIIfaX23Z2M+ua2cL1vwH8GoAX9sowIcTespuP8ScAfKFK+lgH8N/d/U+jAe7AiEQhBcoQ+qS8UuFB2Z8Rl1YGJHoNABotHqVWa6bLAs0TuQsALIjImkyCgw7kvKhM0urKetqOCZf5+kEyx4UFfmxH5rksZ2VaKqtFkWFB/spej5/PzSCibOlQeq6KKPElsR0AOoFE3Nvg16MVtx4RF+QcRTCNlNt2dnf/PoA33e54IcRskfQmRCbI2YXIBDm7EJkgZxciE+TsQmTCTBNOAk6jcgZDLg3NtdIP43TnuEw2aXDdIqpfVie16ADgR5fT8T69AU982Z1bpH3tBk8qOR7xSLR2kHASJPmlBXJjp8F1nEkgYc4HEX3DrbR8NQwi/WqBpNjuBOc6kN7YUc91ue39AT/mxUUuRW5u8HiwTrtL+5wkv5wE2ltJ6g5G6M4uRCbI2YXIBDm7EJkgZxciE+TsQmTCTFfji6JAh6yqToZ8BbRWS6/SsnYA6ATBKXWS8wsARkGEAct55xMewbG+vMLtcK4KNAu+ze4it79m6VO6NeBBGseP8oCWfrAiPJ7wbdbJXEUr3Z0WVyfqdF0dKEhuQAAYj9M2rq7yYJd+kJ+u0UgHQwFALchtiGD1vE6CcmoeBeuQ6yMIkNGdXYhMkLMLkQlydiEyQc4uRCbI2YXIBDm7EJkwc+ltbi4dgLDS58Ek43FatnDn5keyXFAhB70eD0Bh22wHUh5GXDKaDHmJKmvwcScOvZb2/d3588n2o0s8IOfw4cO0b22LS4C9LS69jYjkFWUY5kcMTEreWwZ9W6SMVlRaKSorVk74/bEeSG9h2SiSgHE85vJgyTS24NrWnV2ITJCzC5EJcnYhMkHOLkQmyNmFyAQ5uxCZsK30ZmaPA/h1AJfc/Y1V2xEAnwVwD4CXALzX3Ze325a701I3FkQujYZpCWJtjUsTtUWeY8yCiLJIu2ARe6Mel9COHuGyVq3Oc6c1Jnybw7V0iScA2FpPS01dcKnp8vnLtG+lx+W1IohSa7TT0WFlkAtvQuQ6ANgKouWaBZdZWWmubpfnhFsL5rfZ4LnwepvcxtVVXmKLReY1SLkxABgP+bXD2Mmd/Y8APHhT26MAnnb3ewE8Xf0vhLiD2dbZq3rr125qfieAJ6q/nwDwrr01Swix19zud/YT7n4BAKrfx/fOJCHEfrDvj8ua2RkAZwCg3eHf8YQQ+8vt3tkvmtlJAKh+X2IvdPez7n7a3U83WnzBQQixv9yusz8F4KHq74cAfHFvzBFC7Bc7kd4+A+BtAI6a2SsAPgjgQwA+Z2YPA3gZwHt2a0gkhQx6adliPOZSx3DEZblAqUEQQAXU0u+NhxZ5wsZRUO6oHRjifS69/ejlH9C+paWTyfb+xgods7q6Rvs2RlyKXDzBL59xkZ7IYVCqqR588msGff01HjG5uJiO9usFcmkjKK9VI9cAALRImTIAKElZLgAoiOrcDCIEJyQZZSRhb+vs7v4+0vX27cYKIe4c9ASdEJkgZxciE+TsQmSCnF2ITJCzC5EJM004CQATIkFEZbJqjbREVdSCmm2BZNQh2wOAdjOQXYgk40FSyfVNHu1U1vi+DrV41F5vi0uOyz9IJ5yslzyirN3h8zjX5n1LR4/RvotXLybbPcqIOOLRiIGihHpwPnu9tCxXD+S1Tps/6bmxvsrtiGS5IIJtOExfP4MBl49bzXT0nTEdD7qzC5ENcnYhMkHOLkQmyNmFyAQ5uxCZIGcXIhNmKr25lxgP07KR1wJthbwllR5EjRl/H9sKJI1jh3j03fxCuu+HP0zLTAAwafDjmkQJBTtcemt2eJTdtRe/m2wvgmSOJ+Z4EsX5I+mEjQAwCa6eJqnpNwrmHpNAlgsqwXXnuf3r6+nkkfUGn/vRmEcqTka8zyb8eqwF1+NomD434wmfq0adHLNqvQkh5OxCZIKcXYhMkLMLkQlydiEyYbar8WWJST9dngg1vpLZCFZOGWWQTK6c8JXpzY2g7BJZiR1HieuC4xobXzrdDHLoHT3MA1DarbRi4AWZdwAerHTXGtzGwYAH+YyG6f35JMhBFyUHdG7HMAgMahPFox6sjkfBOuNITSi5/QWC3HAsICqYj/4Wmd/gWtSdXYhMkLMLkQlydiEyQc4uRCbI2YXIBDm7EJmwk/JPjwP4dQCX3P2NVdtjAH4LwOXqZR9w9y9tuzd3GAnIGA+4HMasbLa4+Y1OEJRQ52V1omRnhvQ2l5aO0DGXr9xc2v7/M7cQBLsEdnQXeODHEWLL5gqtvYnxiEtXG2tXad/SCS4BrhBZrhXk3WsE+dPKMZeUNje5/adee4r2Ma5cvkz7mnUuA7ca/Hz2+zx3nXn62p8Ex1wEeffomB285o8APJho/6i731f9bO/oQogDZVtnd/dnAPDbkxDix4LdfGd/xMyeN7PHzezwnlkkhNgXbtfZPw7g9QDuA3ABwIfZC83sjJmdM7Nz4xF/VFIIsb/clrO7+0V3n7h7CeATAO4PXnvW3U+7++koMb8QYn+5LWc3s5M3/PtuAC/sjTlCiP1iJ9LbZwC8DcBRM3sFwAcBvM3M7sM049VLAH57JzsrzNAkEWxlwSONnEQ8laSUFAA0moG8FjAe8xJEbVaSKYigOnrsKO0rwO1vtrm0Mil55FWdzONdh5fomOVNLsutLPMowPlDi7SvmKTncX5+gY6ZkFxsABAECKLb4FLk5ko6B12rxctaYcx31qrx62p9dYX2Dfv8nLG8fBPn11WNSJhRFr9tnd3d35do/uR244QQdxZ6gk6ITJCzC5EJcnYhMkHOLkQmyNmFyISZPuViRQ2NdrqcUBAMhX5/M9k+GvMkiltbXEIrCi6flHwYtnppiaS9yCWok6deQ/sGWzwSqtfnyRzn21w2arfT7etX1+iYIN8kLKjxtHo1LWsBwLCXlhXXxnxMJ0gsWg/OWW8jfX0AwGp/Jdl++DB/wrtV8PldWeZhIlevLdO+uW6wP3Lc/VFwMYYiWxrd2YXIBDm7EJkgZxciE+TsQmSCnF2ITJCzC5EJsw0wLwrU2umop40eT/JXNNMyTrsTmB8k62sGcfWTIIJti0QuXVvmkos1eBLFuTbf1+oal3hOHr+L9t37M69Ntr/wLN9eb53PVX/EJZ7RmMuDLVLjbj2QycbkPAOAOZ/HzR6PzCuK9Bxbyee+0eAy3yiKzAvqudWCum0sQHMYRN8h2BdDd3YhMkHOLkQmyNmFyAQ5uxCZIGcXIhNmnO7VMCGrkq05nkes3U2vPHYa/L1q+TxfKUaU0jqIPaiTBdXhkOcXG6zzAJROrUv7xiQvGQBsbvJjOzSfXtptd3iQia3xgKLxgM9VUed93UPpfH2XL/BAmEPzPKBoa5PbOBoGuQhb6eNe3+R2zHV5GadxsApeBkqOB57WtHTneCO6hsm+SL5GQHd2IbJBzi5EJsjZhcgEObsQmSBnFyIT5OxCZMJOyj/dDeBTAF6Dabays+7+MTM7AuCzAO7BtATUe92dR4QAgAF1EhiytcHlkxrRw1p1HrDQbXNZqxgGSdeCJHRFI629LcxxySgqQ9WqBWWjlo7Qvrk2l4Z6/X6yfbPHpat6MI91HveBuTku59117FCyfeUaD8jxoByW1bjkNZzw8+mePp814+fZwA+6jIJkikCWK/j+nMh5tXqwPVKmjJVKA3Z2Zx8D+H13/zkAbwXwu2b2BgCPAnja3e8F8HT1vxDiDmVbZ3f3C+7+jervdQAvAjgF4J0Anqhe9gSAd+2TjUKIPeCWvrOb2T0A3gzgawBOuPsFYPqGAOD4nlsnhNgzduzsZjYP4EkA73f3IAn5Pxh3xszOmdm5YX9wOzYKIfaAHTm7mTUwdfRPu/vnq+aLZnay6j8JIFnk293Puvtpdz/dDIobCCH2l22d3cwM03rsL7r7R27oegrAQ9XfDwH44t6bJ4TYK3YS9fYAgN8E8C0ze65q+wCADwH4nJk9DOBlAO/ZbkPmjto4LQ21g4ih8VpaZuiPeGTYeMTlmE5Qa8qDsjpMPGk2uQS1uJjOuQcACOSfw0tczmsG9vfW0yWlSufzUa/z7dUbXA6bBHnc1lbT8lURlFY6dvwYt6PO5/j8tb+ifY1muh5WrcMltKEF0XyL6fJlANANouWGI54nr7ee7msFn4T7vUA+Jmzr7O7+VfDsdm+/5T0KIQ4EPUEnRCbI2YXIBDm7EJkgZxciE+TsQmTCbBNOlhP4VjqJXjHikUZOopo2t/gTebVADuu0eXLLSSBRrQ3SkWP1oJxUWfLtlRMuHV4LElUuBbJcYWnh5MiRw3TMcMjlxmHwrORGn0tUa7X0uenMcXlqZW2F9k2CaK5akEyzIBLbIIiwi6iXfJyPg6g94/bPz6evx+WraZm62mLQl0Z3diEyQc4uRCbI2YXIBDm7EJkgZxciE+TsQmTCbKU3d2CclmQaQbK+7lxaNpoE6sPAuazV2+LJF6MEkd1uOollUSNF4BBH0XWaQQTYIpfX2h0+7tq1dM7PWpCwMUoc+bogau87L/097WvPpaPNRgNev2xryM/LhE8jECV6JJJXkOsTpQVyKUlgud02I6WMXT+tNr8WNzfSc7XbhJNCiJ8A5OxCZIKcXYhMkLMLkQlydiEyYaar8e6O0SgdLNBd5MEpo1F6Bb8s+Cr4IAgy6RgfN5nw1dYJyWs3mPAgnsU5XobqULDS3QqOzckcAsCYlAVqtfgKfrudXjkHgHUy9wAwKvnquTXTNi4GgTDDHt9Xb42v4i8u8G022mmlodaKyknxa2djI53jDwBOHX8NH9db4fsjJbui3Ia3g+7sQmSCnF2ITJCzC5EJcnYhMkHOLkQmyNmFyIRtpTczuxvApwC8BkAJ4Ky7f8zMHgPwWwAuVy/9gLt/aZuNAfX0w/1lwR/gH5dpacvBAwXqQXBKMyglNAxKSrFcbcMJl8IaQVmr+uEl2jcJ5LVanR9bq5WW0azg8mB3nktvK1fXad/d9/ByTUUtPVfdIOgGQf6//iVePml+8RDta5G5Kur8vLRbfH7HLX59NFv82Noln+NBPz3HkQzMSnYZyUEI7ExnHwP4fXf/hpktAHjWzL5S9X3U3f/zDrYhhDhgdlLr7QKAC9Xf62b2IoBT+22YEGJvuaXv7GZ2D4A3A/ha1fSImT1vZo+bGc9VLIQ4cHbs7GY2D+BJAO939zUAHwfwegD3YXrn/zAZd8bMzpnZueGQf28UQuwvO3J2M2tg6uifdvfPA4C7X3T3ibuXAD4B4P7UWHc/6+6n3f10M8gCI4TYX7Z1dpsu730SwIvu/pEb2k/e8LJ3A3hh780TQuwVO1mNfwDAbwL4lpk9V7V9AMD7zOw+AA7gJQC/vd2GHMCQqCtFjUe9tVrpTwTDAZdB2kGUV6cTRHld5dFV1khLMu0oB1qfR4aNST4+AKg1+PvwaMjLAi210xFgy0F+t80gem3h+Dztawy41MSqJA2GXELzgktNdx0/QvtGwXWAMi0BjoLSYY02P59m3MZGg39yHSxzWRF+68GntXr6uALlbUer8V9FOl1erKkLIe4o9ASdEJkgZxciE+TsQmSCnF2ITJCzC5EJM004WbpjQDSZos7lsDrSYyLJxYIyOKMxjyhrtrlkx8oMNYPaPp3gQaJaUC/IA+ltY5VHojUmaYmndH7ML//oCu07/NqjtG/Y5zLUYDMtsVk9SOgZ1HiqB5F+VvK5GpNzPRzza8cDKXUw4NLh1haXbaMoTJYktNHkPlH6ZrI9KjemO7sQmSBnFyIT5OxCZIKcXYhMkLMLkQlydiEyYabSW1EUaM+lo9vWemkpAeBRZU2yLQAwixJY8gikFokaA4DBKJ18owxkvlaX13oL4qDCumdRIsLS0jaOAqlpcWGJ9vmYXyKDINHmAGkbD3f4OVsKzufGKr8+VoN6dMNhum8YyK+tLrfjyGEefdcnNduAaZ1DBrNxRGoLAlzKC4LedGcXIhfk7EJkgpxdiEyQswuRCXJ2ITJBzi5EJsxUejMzNEiNKi5MABOiJ/QCyWWuyZMhdhcWaN/WkEsyLLpqQmrRAUBvwPsaQW2wqNZbVM+r1U1H7TXG3I7Sg4iyCb9Eev1br3vmJAEkALTbPEJwM5Aba6Su3LQvPVeTAZe1Ismr2+FRkb0NnrjTg8i8kkSCjkbBMRfEjuDa0J1diEyQswuRCXJ2ITJBzi5EJsjZhciEbVfjzawN4BkArer1f+LuHzSzIwA+C+AeTMs/vdfdl8NtAah7erWwHuRjMxIyEuXbsjrfXpDqDG58SlgQj4OvSveDnGVY58EdiAJX5viK8DoJoCnJvANAvx+UQgouEQ8Ciko2yUFuPZYvDgDGrJ4UgKPHeHBKd5BWGgavXKRjSr4IHto4DEpsNeo8uGaum841R1fcAaws83PG2MmdfQDgV9z9TZiWZ37QzN4K4FEAT7v7vQCerv4XQtyhbOvsPuV62sxG9eMA3gngiar9CQDv2g8DhRB7w07rs9eqCq6XAHzF3b8G4IS7XwCA6vfxfbNSCLFrduTs7j5x9/sAvA7A/Wb2xp3uwMzOmNk5Mzs3DJ4mE0LsL7e0Gu/uKwD+F4AHAVw0s5MAUP2+RMacdffT7n66SeqsCyH2n22d3cyOmdlS9XcHwK8C+A6ApwA8VL3sIQBf3CcbhRB7wE4CYU4CeMLMapi+OXzO3f+nmf1vAJ8zs4cBvAzgPdttqIBhjklbgRxmJAedN3ggSRnkoIvyj01KPiVFkZZx3HggSdHk8kmjwfdVq/G+kpR4AoCVlXQetKLBbey0g1x+we2gGZ0zIr1ZkCVtEGhe1uTz0QmCU64urybb5zo8N2ArkDYnEy6lRiWqYFHGQdbHx0S55hjbOru7Pw/gzYn2qwDefhv7FEIcAHqCTohMkLMLkQlydiEyQc4uRCbI2YXIBIvK0uz5zswuA/j76t+jAK7MbOcc2fFqZMer+XGz4x+7+7FUx0yd/VU7Njvn7qcPZOeyQ3ZkaIc+xguRCXJ2ITLhIJ397AHu+0Zkx6uRHa/mJ8aOA/vOLoSYLfoYL0QmHIizm9mDZvZ/zex7ZnZguevM7CUz+5aZPWdm52a438fN7JKZvXBD2xEz+4qZfbf6ffiA7HjMzH5YzclzZvaOGdhxt5n9hZm9aGbfNrPfq9pnOieBHTOdEzNrm9n/MbNvVnb8h6p9d/Ph7jP9AVAD8LcAfhpAE8A3Abxh1nZUtrwE4OgB7PeXAbwFwAs3tP0nAI9Wfz8K4D8ekB2PAfiDGc/HSQBvqf5eAPA3AN4w6zkJ7JjpnGAawTpf/d0A8DUAb93tfBzEnf1+AN9z9++7+xDAH2OavDIb3P0ZANduap55Ak9ix8xx9wvu/o3q73UALwI4hRnPSWDHTPEpe57k9SCc/RSAH9zw/ys4gAmtcABfNrNnzezMAdlwnTspgecjZvZ89TF/379O3IiZ3YNp/oQDTWp6kx3AjOdkP5K8HoSzp5JsHJQk8IC7vwXAvwbwu2b2ywdkx53ExwG8HtMaARcAfHhWOzazeQBPAni/u6/Nar87sGPmc+K7SPLKOAhnfwXA3Tf8/zoA5w/ADrj7+er3JQBfwPQrxkGxowSe+427X6wutBLAJzCjOTGzBqYO9ml3/3zVPPM5SdlxUHNS7XsFt5jklXEQzv51APea2U+ZWRPAb2CavHKmmFnXzBau/w3g1wC8EI/aV+6IBJ7XL6aKd2MGc2JmBuCTAF5094/c0DXTOWF2zHpO9i3J66xWGG9abXwHpiudfwvgDw/Ihp/GVAn4JoBvz9IOAJ/B9OPgCNNPOg8DuAvTMlrfrX4fOSA7/huAbwF4vrq4Ts7Ajl/C9Kvc8wCeq37eMes5CeyY6ZwA+AUAf1Xt7wUA/75q39V86Ak6ITJBT9AJkQlydiEyQc4uRCbI2YXIBDm7EJkgZxfXo7r+4KDtEPuLnF3sCWasYqe4U5CzZ4qZ/WGVU+DPAfxs1fZ6M/vTKjDoL83sn1Ttx8zsSTP7evXzQNX+mJmdNbMvA/jUwR2N2Al6N84QM/tFTB9TfjOm18A3ADyLaZ6z33H375rZPwXwXwD8CoCPAfiou3/VzP4RgD8D8HPV5n4RwC+5+9aMD0PcInL2PPkXAL7g7j0AMLOnALQB/HMA/2P6iDgA4Hqh8l8F8IYb2hevxxUAeEqO/uOBnD1fbn5OugCw4tOwypspAPyzm526cv7NfbFO7Dn6zp4nzwB4t5l1qjv0vwHQA/B3ZvYeYBoBZmZvql7/ZQCPXB9sZvfN2F6xB8jZM8SnqZc+i2lU15MA/rLq+rcAHjaz65GA19OF/TsAp6tMLX8N4Hdma7HYCxT1JkQm6M4uRCbI2YXIBDm7EJkgZxciE+TsQmSCnF2ITJCzC5EJcnYhMuH/AS5iYqAwG/7bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_INDEX = 10\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX], cmap= plt.cm.binary)\n",
    "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6a0f50",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f589cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(layers.MaxPooling2D((2,2))) ## reduce the dimensionality\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331794e",
   "metadata": {},
   "source": [
    "### Layer 1\n",
    "\n",
    "The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.\n",
    "\n",
    "### Layer 2\n",
    "\n",
    "This layer will perform the max pooling operation using 2x2 samples and a stride of 2.\n",
    "\n",
    "### Other Layers\n",
    "\n",
    "The next set of layers do very similar things but take as input the feature map from the previous layer. They also increase the frequency of filters from 32 to 64. We can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford (computationally) to add more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b79652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafe1cb1",
   "metadata": {},
   "source": [
    "## Adding Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5407dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(10)) ## b/c we've 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11f7ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554ccb22",
   "metadata": {},
   "source": [
    "## Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "688188c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 51s 27ms/step - loss: 1.9568 - accuracy: 0.3570 - val_loss: 2.3236 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.3766 - accuracy: 0.5056 - val_loss: 2.3686 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 1.2182 - accuracy: 0.5683 - val_loss: 2.4567 - val_accuracy: 0.1173\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 1.1099 - accuracy: 0.6078 - val_loss: 2.5382 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 1.0397 - accuracy: 0.6384 - val_loss: 2.6714 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 49s 31ms/step - loss: 0.9577 - accuracy: 0.6671 - val_loss: 2.7385 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.8991 - accuracy: 0.6862 - val_loss: 2.9520 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 40s 26ms/step - loss: 0.8510 - accuracy: 0.7058 - val_loss: 2.8998 - val_accuracy: 0.1006\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8041 - accuracy: 0.7180 - val_loss: 2.7412 - val_accuracy: 0.1003\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7575 - accuracy: 0.7362 - val_loss: 2.9233 - val_accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_lables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e235cced",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfbaec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 4s - loss: 2.9233 - accuracy: 0.1000 - 4s/epoch - 13ms/step\n",
      "0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_lables, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd95b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e055b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547ede9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
